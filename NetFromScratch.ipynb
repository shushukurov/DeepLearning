{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_!.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzS3CA3rZpbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgOYgSRTlXH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.tensor(([2,9],[1,5],[3,6]),dtype=torch.float) # 3x2 tensor\n",
        "y = torch.tensor(([92],[100],[89]),dtype=torch.float) # 3X1 tensor\n",
        "xPredicted = torch.tensor(([4,8]),dtype=torch.float) # 2X1 tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRjKpYgANtxi",
        "colab_type": "code",
        "outputId": "706312d4-ddb8-492c-afec-92f43a1b4313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X.size())\n",
        "print(y.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2])\n",
            "torch.Size([3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUB1rl1aNxOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Scale units\n",
        "X_max, _ = torch.max(X,0) # dummy variable to capture and drop indices (we only need max value)\n",
        "xPredicted_max, _ = torch.max(xPredicted,0)\n",
        "#Dividing tensors\n",
        "X = torch.div(X, X_max)\n",
        "xPredicted = torch.div(xPredicted,xPredicted_max)\n",
        "y = y /100 # max test score is 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOKOdLCtN2co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Neural_Network(nn.Module):\n",
        "  def __init__(self,):\n",
        "    super(Neural_Network,self).__init__()\n",
        "    #Parametres\n",
        "    #TODO: parameters can be parameterized instead of declaring them here\n",
        "    self.inputSize = 2\n",
        "    self.outputSize = 1\n",
        "    self.hiddenSize = 3\n",
        "    self.intermediate = 3\n",
        "\n",
        "    #weights\n",
        "    self.W1 = torch.randn(self.inputSize, self.hiddenSize) # 2X3 tensor\n",
        "    self.WI = torch.randn(self.hiddenSize,self.intermediate) # 3x3 tensor \n",
        "    self.W2 = torch.randn(self.intermediate,self.outputSize) # 3x1 tensor\n",
        "\n",
        "  \n",
        "  def forward(self, X):\n",
        "    self.z = torch.matmul(X,self.W1) #3x3\n",
        "    self.z2 = self.sigmoid(self.z) # activation function\n",
        "    self.ZI = torch.matmul(self.z2,self.WI)\n",
        "    self.zi1 = self.sigmoid(self.ZI)\n",
        "    self.z3 = torch.matmul(self.zi1, self.W2)\n",
        "    o = self.sigmoid(self.z3) # final activation\n",
        "    return o\n",
        "  \n",
        "  def sigmoid(self,s):\n",
        "    return 1 / (1+torch.exp(-s))\n",
        "\n",
        "  def sigmoidPrime(self,s):\n",
        "    #derivative of sigmoid\n",
        "    return s * (1 - s)\n",
        "\n",
        "  def backward(self, X, y, o):\n",
        "    self.o_error = y - 0 #error in output\n",
        "    self.o_delta = self.o_error * self.sigmoidPrime(o) # derivative of sigmoid to error\n",
        "    self.ZI_error = torch.matmul(self.o_delta,torch.t(self.W2))\n",
        "    self.ZI_delta = self.ZI_error * self.sigmoidPrime(self.ZI) # derivative of inter hidden layer\n",
        "    self.z2_error = torch.matmul(self.ZI_delta,torch.t(self.WI)) # error of 1 hidden layer\n",
        "    self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2) # derivative of 1 hidden layer\n",
        "    self.W1 += torch.matmul(torch.t(X), self.z2_delta) \n",
        "    self.WI += torch.matmul(torch.t(self.z2),self.ZI_delta)\n",
        "    self.W2 += torch.matmul(torch.t(self.zi1), self.o_delta)\n",
        "\n",
        "  def train(self, X,y):\n",
        "    #forward + backward pass for training\n",
        "    o = self.forward(X)\n",
        "    self.backward(X,y,o)\n",
        "\n",
        "  def saveWeights(self,model):\n",
        "    #we will use the pytorch internal storage function\n",
        "    torch.save(model, 'NN')\n",
        "    # you can reload model with all the weights and so forth with:\n",
        "    # torch.load('NN')\n",
        "\n",
        "  def predict(self):\n",
        "    print('Predicted data based on trained weights :')\n",
        "    print('Input (scaled): \\n' + str(xPredicted))\n",
        "    print('Output: \\n'+ str(self.forward(xPredicted)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtMKQ1es38jl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training process\n",
        "NN = Neural_Network()\n",
        "for i in range(1000):\n",
        "  print('#'+str(i)+\" Loss: \" + str(torch.mean((y-NN(X))**2).detach().item()))\n",
        "  NN.train(X,y)\n",
        "NN.saveWeights(NN)\n",
        "NN.predict()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}